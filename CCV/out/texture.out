{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'random', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Random_ViT/Texture/', 'results_dir': './Results/Random_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 0, 'operation': 'attn', 'mask_init_value': 0.0, 'seed': 0}
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'imagenet', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Imagenet_ViT/Texture/', 'results_dir': './Results/Imagenet_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 0, 'operation': 'attn', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.0.attention.attention.query.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.0.attention.attention.key.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.0.attention.attention.value.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.0.attention.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'imagenet', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Imagenet_ViT/Texture/', 'results_dir': './Results/Imagenet_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 0, 'operation': 'mlp', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.0.attention.attention.query.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.0.attention.attention.key.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.0.attention.attention.value.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.0.attention.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'random', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Random_ViT/Texture/', 'results_dir': './Results/Random_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 0, 'operation': 'mlp', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.0.intermediate.dense.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.0.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'imagenet', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Imagenet_ViT/Texture/', 'results_dir': './Results/Imagenet_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 1, 'operation': 'attn', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.0.intermediate.dense.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.0.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'random', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Random_ViT/Texture/', 'results_dir': './Results/Random_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 1, 'operation': 'attn', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.1.attention.attention.query.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.1.attention.attention.key.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.1.attention.attention.value.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.1.attention.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'imagenet', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Imagenet_ViT/Texture/', 'results_dir': './Results/Imagenet_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 1, 'operation': 'mlp', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.1.attention.attention.query.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.1.attention.attention.key.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.1.attention.attention.value.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.1.attention.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'random', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Random_ViT/Texture/', 'results_dir': './Results/Random_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 1, 'operation': 'mlp', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.1.intermediate.dense.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.1.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'imagenet', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Imagenet_ViT/Texture/', 'results_dir': './Results/Imagenet_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 2, 'operation': 'attn', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.1.intermediate.dense.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.1.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'random', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Random_ViT/Texture/', 'results_dir': './Results/Random_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 2, 'operation': 'attn', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.2.attention.attention.query.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.2.attention.attention.key.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.2.attention.attention.value.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.2.attention.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'imagenet', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Imagenet_ViT/Texture/', 'results_dir': './Results/Imagenet_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 2, 'operation': 'mlp', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.2.attention.attention.query.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.2.attention.attention.key.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.2.attention.attention.value.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.2.attention.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'random', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Random_ViT/Texture/', 'results_dir': './Results/Random_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 2, 'operation': 'mlp', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.2.intermediate.dense.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.2.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'imagenet', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Imagenet_ViT/Texture/', 'results_dir': './Results/Imagenet_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 3, 'operation': 'attn', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.2.intermediate.dense.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.2.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'random', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Random_ViT/Texture/', 'results_dir': './Results/Random_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 3, 'operation': 'attn', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.3.attention.attention.query.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.3.attention.attention.key.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.3.attention.attention.value.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.3.attention.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'imagenet', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Imagenet_ViT/Texture/', 'results_dir': './Results/Imagenet_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 3, 'operation': 'mlp', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.3.attention.attention.query.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.3.attention.attention.key.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.3.attention.attention.value.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.3.attention.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'random', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Random_ViT/Texture/', 'results_dir': './Results/Random_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 3, 'operation': 'mlp', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.3.intermediate.dense.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.3.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'imagenet', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Imagenet_ViT/Texture/', 'results_dir': './Results/Imagenet_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 4, 'operation': 'attn', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.3.intermediate.dense.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.3.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'random', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Random_ViT/Texture/', 'results_dir': './Results/Random_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 4, 'operation': 'attn', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.4.attention.attention.query.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.4.attention.attention.key.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.4.attention.attention.value.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.4.attention.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'imagenet', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Imagenet_ViT/Texture/', 'results_dir': './Results/Imagenet_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 4, 'operation': 'mlp', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.4.attention.attention.query.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.4.attention.attention.key.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.4.attention.attention.value.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.4.attention.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'random', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Random_ViT/Texture/', 'results_dir': './Results/Random_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 4, 'operation': 'mlp', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.4.intermediate.dense.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.4.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'random', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Random_ViT/Texture/', 'results_dir': './Results/Random_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 5, 'operation': 'attn', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.4.intermediate.dense.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.4.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'imagenet', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Imagenet_ViT/Texture/', 'results_dir': './Results/Imagenet_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 5, 'operation': 'attn', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.5.attention.attention.query.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.5.attention.attention.key.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.5.attention.attention.value.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.5.attention.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'random', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Random_ViT/Texture/', 'results_dir': './Results/Random_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 5, 'operation': 'mlp', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.5.attention.attention.query.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.5.attention.attention.key.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.5.attention.attention.value.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.5.attention.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'imagenet', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Imagenet_ViT/Texture/', 'results_dir': './Results/Imagenet_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 5, 'operation': 'mlp', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.5.intermediate.dense.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.5.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'random', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Random_ViT/Texture/', 'results_dir': './Results/Random_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 6, 'operation': 'attn', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.5.intermediate.dense.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.5.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'imagenet', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Imagenet_ViT/Texture/', 'results_dir': './Results/Imagenet_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 6, 'operation': 'attn', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.6.attention.attention.query.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.6.attention.attention.key.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.6.attention.attention.value.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.6.attention.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'random', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Random_ViT/Texture/', 'results_dir': './Results/Random_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 6, 'operation': 'mlp', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.6.attention.attention.query.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.6.attention.attention.key.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.6.attention.attention.value.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.6.attention.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'imagenet', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Imagenet_ViT/Texture/', 'results_dir': './Results/Imagenet_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 6, 'operation': 'mlp', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.6.intermediate.dense.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.6.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'random', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Random_ViT/Texture/', 'results_dir': './Results/Random_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 7, 'operation': 'attn', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.6.intermediate.dense.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.6.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'imagenet', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Imagenet_ViT/Texture/', 'results_dir': './Results/Imagenet_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 7, 'operation': 'attn', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.7.attention.attention.query.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.7.attention.attention.key.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.7.attention.attention.value.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.7.attention.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'random', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Random_ViT/Texture/', 'results_dir': './Results/Random_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 7, 'operation': 'mlp', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.7.attention.attention.query.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.7.attention.attention.key.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.7.attention.attention.value.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.7.attention.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'imagenet', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Imagenet_ViT/Texture/', 'results_dir': './Results/Imagenet_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 7, 'operation': 'mlp', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.7.intermediate.dense.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.7.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'random', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Random_ViT/Texture/', 'results_dir': './Results/Random_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 8, 'operation': 'attn', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.7.intermediate.dense.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.7.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'imagenet', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Imagenet_ViT/Texture/', 'results_dir': './Results/Imagenet_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 8, 'operation': 'attn', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.8.attention.attention.query.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.8.attention.attention.key.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.8.attention.attention.value.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.8.attention.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'random', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Random_ViT/Texture/', 'results_dir': './Results/Random_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 8, 'operation': 'mlp', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.8.attention.attention.query.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.8.attention.attention.key.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.8.attention.attention.value.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.8.attention.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'imagenet', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Imagenet_ViT/Texture/', 'results_dir': './Results/Imagenet_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 8, 'operation': 'mlp', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.8.intermediate.dense.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.8.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'random', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Random_ViT/Texture/', 'results_dir': './Results/Random_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 9, 'operation': 'attn', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.8.intermediate.dense.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.8.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'imagenet', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Imagenet_ViT/Texture/', 'results_dir': './Results/Imagenet_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 9, 'operation': 'attn', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.9.attention.attention.query.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.9.attention.attention.key.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.9.attention.attention.value.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.9.attention.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'random', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Random_ViT/Texture/', 'results_dir': './Results/Random_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 9, 'operation': 'mlp', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.9.attention.attention.query.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.9.attention.attention.key.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.9.attention.attention.value.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.9.attention.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'imagenet', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Imagenet_ViT/Texture/', 'results_dir': './Results/Imagenet_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 9, 'operation': 'mlp', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.9.intermediate.dense.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.9.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'random', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Random_ViT/Texture/', 'results_dir': './Results/Random_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 10, 'operation': 'attn', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.9.intermediate.dense.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.9.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'imagenet', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Imagenet_ViT/Texture/', 'results_dir': './Results/Imagenet_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 10, 'operation': 'attn', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.10.attention.attention.query.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.10.attention.attention.key.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.10.attention.attention.value.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.10.attention.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'random', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Random_ViT/Texture/', 'results_dir': './Results/Random_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 10, 'operation': 'mlp', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.10.attention.attention.query.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.10.attention.attention.key.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.10.attention.attention.value.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.10.attention.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'imagenet', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Imagenet_ViT/Texture/', 'results_dir': './Results/Imagenet_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 10, 'operation': 'mlp', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.10.intermediate.dense.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.10.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'random', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Random_ViT/Texture/', 'results_dir': './Results/Random_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 11, 'operation': 'attn', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.10.intermediate.dense.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.10.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'imagenet', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Imagenet_ViT/Texture/', 'results_dir': './Results/Imagenet_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 11, 'operation': 'attn', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.11.attention.attention.query.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.11.attention.attention.key.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.11.attention.attention.value.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.11.attention.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'random', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Random_ViT/Texture/', 'results_dir': './Results/Random_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 11, 'operation': 'mlp', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.11.attention.attention.query.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.11.attention.attention.key.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.11.attention.attention.value.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.11.attention.output.dense.weight_mask_params
Saving csv
{'target_layer_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'operation_list': ['attn', 'mlp'], 'mask_init_list': [0.0], 'max_temp': 200, 'pretrain': 'imagenet', 'patch_size': '32', 'device': device(type='cuda'), 'variable': 't', 'train_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/train', 'test_dir': 'stimuli/SHAPES/aligned/N_32/trainsize_6400_1200-300-100/test', 'train_size': 2000, 'test_size': 1000, 'num_epochs': 90, 'lr_list': [0.001], 'batch_size_list': [500], 'l0_lambda': 1e-07, 'seed_list': [0], 'num_random_ablations': 5, 'sd_eval': True, 'model_dir': './Model/Imagenet_ViT/Texture/', 'results_dir': './Results/Imagenet_ViT/Texture/', 'save_models': False, 'lr': 0.001, 'batch_size': 500, 'target_layer': 11, 'operation': 'mlp', 'mask_init_value': 0.0, 'seed': 0}
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.11.intermediate.dense.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.11.output.dense.weight_mask_params
Saving csv
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.11.intermediate.dense.weight_mask_params
wrapped_model.wrapped_model.wrapped_model.vit.encoder.layer.11.output.dense.weight_mask_params
Saving csv
